{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9648,
     "status": "ok",
     "timestamp": 1575046134860,
     "user": {
      "displayName": "Forest Fire",
      "photoUrl": "",
      "userId": "18339125348470227546"
     },
     "user_tz": -480
    },
    "id": "2vVp2x11tJgy",
    "outputId": "f6f262da-f769-4bc5-bac6-9d2465754282"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "samples = []\n",
    "labels = []\n",
    "images_folder = \"images/\"\n",
    "image_list = os.listdir(images_folder)\n",
    "random.seed(10)\n",
    "random.shuffle(image_list)\n",
    "\n",
    "for image in image_list:\n",
    "    samples.append(img_to_array(load_img(images_folder + image, target_size = (200, 200)))) # Change Target Size accordingly to the resolution.\n",
    "#     print(image)\n",
    "    if \"normal\" in image:\n",
    "        labels.append((0))\n",
    "    else:\n",
    "        labels.append((1))\n",
    "        \n",
    "samples = np.array(samples)\n",
    "labels = np.array(labels)\n",
    "eval_x, eval_y = samples[-100:], labels[-100:] # 2000 images, 100 in evaluation.\n",
    "print(samples.shape, labels.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(samples[:-100], labels[:-100], test_size = 0.2, random_state=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37469,
     "status": "ok",
     "timestamp": 1575047213397,
     "user": {
      "displayName": "Forest Fire",
      "photoUrl": "",
      "userId": "18339125348470227546"
     },
     "user_tz": -480
    },
    "id": "9mJzkL6UtfHa",
    "outputId": "2af1e885-704d-4817-9619-4320dc642336"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.callbacks import History \n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(keras.layers.InputLayer(input_shape=(200, 200, 3)))\n",
    "\n",
    "model.add(keras.layers.convolutional.Conv2D(filters = 16, kernel_size = (3, 3), strides=(1, 1), padding='valid', data_format=\"channels_last\", activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "model.add(keras.layers.Dense(units=1, input_dim=50,activation='sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "history = History()\n",
    "model.fit(x_train, y_train, batch_size = 32, epochs = 50,  callbacks = [history], validation_data = (x_test, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "def plotResults(): \n",
    "    plt.figure()\n",
    "    N = 50\n",
    "    \n",
    "    # TODO: plot the accuracy/loss variables over training time\n",
    "    plt.plot(np.arange(0, N), history.history[\"accuracy\"], label = \"train_acc\")\n",
    "    plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label = \"val_acc\")\n",
    "\n",
    "    # make the graph understandable: \n",
    "    plt.title(\"Training Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.yscale('log')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, N), history.history[\"loss\"], label = \"train_loss\")\n",
    "    plt.plot(np.arange(0, N), history.history[\"val_loss\"], label = \"val_loss\")\n",
    "    \n",
    "     # make the graph understandable: \n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.yscale('log')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('basic-model.h5')\n",
    "plotResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_on_training_set(y_test, y_pred):\n",
    "    \n",
    "    # Calculate AUC\n",
    "    print(\"AUC  is:  \",  roc_auc_score(y_test,  y_pred))\n",
    "    \n",
    "    # print out recall and precision\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # print out confusion matrix\n",
    "    print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # # calculate points for ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr,  tpr,  label='ROC  curve  (area  =  %0.3f)'  %  roc_auc_score(y_test,  y_pred)) \n",
    "    plt.plot([0,  1],  [0,  1],  'k--') #  random  predictions  curve\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False  Positive  Rate  or  (1  -  Specifity)') \n",
    "    plt.ylabel('True  Positive  Rate  or  (Sensitivity)') \n",
    "    plt.title('Receiver  Operating  Characteristic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 743,
     "status": "ok",
     "timestamp": 1575047220828,
     "user": {
      "displayName": "Forest Fire",
      "photoUrl": "",
      "userId": "18339125348470227546"
     },
     "user_tz": -480
    },
    "id": "nuBZJ72Sy-2n",
    "outputId": "6eb16f6c-b206-43bf-e6d5-75c8c27ec436"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(eval_x, eval_y, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vdRJkMIIIUrO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "output = model.predict_classes(eval_x, verbose = 1)\n",
    "pred_y = np.array(output).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loss: {score[0]}\\nAccuracy: {score[1]}\")\n",
    "evaluate_on_training_set(eval_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "new.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
